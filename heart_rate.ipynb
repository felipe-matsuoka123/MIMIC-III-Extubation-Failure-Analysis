{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIMIC-III Extubation Failure Analysis\n",
    "\n",
    "### Code to Select Heart Rate Information from the CHARTEVENTS CSV in MIMIC Clinical\n",
    "\n",
    "In this section, we will use the Polars library to process the large volume of data present in the CHARTEVENTS CSV file from the MIMIC-III dataset. This will allow us to efficiently extract and analyze ***heart rate*** information relevant to our study on extubation failure in ICUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the CHARTEVENTS CSV file\n",
    "CHARTEVENTS = '/Volumes/FelipeSSD/mimic_clinical/CHARTEVENTS.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory (os error 2): /Volumes/FelipeSSD/mimic_clinical/CHARTEVENTS.csv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/felipeakiomatsuoka/Desktop/PIBIC/scripts/heart_rate.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/felipeakiomatsuoka/Desktop/PIBIC/scripts/heart_rate.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m null_values \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mMoves on Bed\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/felipeakiomatsuoka/Desktop/PIBIC/scripts/heart_rate.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Adjusting the infer_schema_length\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/felipeakiomatsuoka/Desktop/PIBIC/scripts/heart_rate.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m charevents \u001b[39m=\u001b[39m pl\u001b[39m.\u001b[39;49mscan_csv(CHARTEVENTS, infer_schema_length\u001b[39m=\u001b[39;49m\u001b[39m100000\u001b[39;49m, dtypes\u001b[39m=\u001b[39;49mdtypes, null_values\u001b[39m=\u001b[39;49mnull_values)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/polars/utils/deprecation.py:100\u001b[0m, in \u001b[0;36mdeprecate_renamed_parameter.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[39m@wraps\u001b[39m(function)\n\u001b[1;32m     96\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs: P\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: P\u001b[39m.\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m     97\u001b[0m     _rename_keyword_argument(\n\u001b[1;32m     98\u001b[0m         old_name, new_name, kwargs, function\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, version\n\u001b[1;32m     99\u001b[0m     )\n\u001b[0;32m--> 100\u001b[0m     \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/polars/io/csv/functions.py:917\u001b[0m, in \u001b[0;36mscan_csv\u001b[0;34m(source, has_header, separator, comment_prefix, quote_char, skip_rows, dtypes, schema, null_values, missing_utf8_is_empty_string, ignore_errors, cache, with_column_names, infer_schema_length, n_rows, encoding, low_memory, rechunk, skip_rows_after_header, row_count_name, row_count_offset, try_parse_dates, eol_char, new_columns, raise_if_empty, truncate_ragged_lines)\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    915\u001b[0m     source \u001b[39m=\u001b[39m [normalize_filepath(source) \u001b[39mfor\u001b[39;00m source \u001b[39min\u001b[39;00m source]\n\u001b[0;32m--> 917\u001b[0m \u001b[39mreturn\u001b[39;00m pl\u001b[39m.\u001b[39;49mLazyFrame\u001b[39m.\u001b[39;49m_scan_csv(\n\u001b[1;32m    918\u001b[0m     source,\n\u001b[1;32m    919\u001b[0m     has_header\u001b[39m=\u001b[39;49mhas_header,\n\u001b[1;32m    920\u001b[0m     separator\u001b[39m=\u001b[39;49mseparator,\n\u001b[1;32m    921\u001b[0m     comment_prefix\u001b[39m=\u001b[39;49mcomment_prefix,\n\u001b[1;32m    922\u001b[0m     quote_char\u001b[39m=\u001b[39;49mquote_char,\n\u001b[1;32m    923\u001b[0m     skip_rows\u001b[39m=\u001b[39;49mskip_rows,\n\u001b[1;32m    924\u001b[0m     dtypes\u001b[39m=\u001b[39;49mdtypes,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    925\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[1;32m    926\u001b[0m     null_values\u001b[39m=\u001b[39;49mnull_values,\n\u001b[1;32m    927\u001b[0m     missing_utf8_is_empty_string\u001b[39m=\u001b[39;49mmissing_utf8_is_empty_string,\n\u001b[1;32m    928\u001b[0m     ignore_errors\u001b[39m=\u001b[39;49mignore_errors,\n\u001b[1;32m    929\u001b[0m     cache\u001b[39m=\u001b[39;49mcache,\n\u001b[1;32m    930\u001b[0m     with_column_names\u001b[39m=\u001b[39;49mwith_column_names,\n\u001b[1;32m    931\u001b[0m     infer_schema_length\u001b[39m=\u001b[39;49minfer_schema_length,\n\u001b[1;32m    932\u001b[0m     n_rows\u001b[39m=\u001b[39;49mn_rows,\n\u001b[1;32m    933\u001b[0m     low_memory\u001b[39m=\u001b[39;49mlow_memory,\n\u001b[1;32m    934\u001b[0m     rechunk\u001b[39m=\u001b[39;49mrechunk,\n\u001b[1;32m    935\u001b[0m     skip_rows_after_header\u001b[39m=\u001b[39;49mskip_rows_after_header,\n\u001b[1;32m    936\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m    937\u001b[0m     row_count_name\u001b[39m=\u001b[39;49mrow_count_name,\n\u001b[1;32m    938\u001b[0m     row_count_offset\u001b[39m=\u001b[39;49mrow_count_offset,\n\u001b[1;32m    939\u001b[0m     try_parse_dates\u001b[39m=\u001b[39;49mtry_parse_dates,\n\u001b[1;32m    940\u001b[0m     eol_char\u001b[39m=\u001b[39;49meol_char,\n\u001b[1;32m    941\u001b[0m     raise_if_empty\u001b[39m=\u001b[39;49mraise_if_empty,\n\u001b[1;32m    942\u001b[0m     truncate_ragged_lines\u001b[39m=\u001b[39;49mtruncate_ragged_lines,\n\u001b[1;32m    943\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/polars/lazyframe/frame.py:374\u001b[0m, in \u001b[0;36mLazyFrame._scan_csv\u001b[0;34m(cls, source, has_header, separator, comment_prefix, quote_char, skip_rows, dtypes, schema, null_values, missing_utf8_is_empty_string, ignore_errors, cache, with_column_names, infer_schema_length, n_rows, encoding, low_memory, rechunk, skip_rows_after_header, row_count_name, row_count_offset, try_parse_dates, eol_char, raise_if_empty, truncate_ragged_lines)\u001b[0m\n\u001b[1;32m    371\u001b[0m     sources \u001b[39m=\u001b[39m []\n\u001b[1;32m    373\u001b[0m \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m)\n\u001b[0;32m--> 374\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ldf \u001b[39m=\u001b[39m PyLazyFrame\u001b[39m.\u001b[39;49mnew_from_csv(\n\u001b[1;32m    375\u001b[0m     source,\n\u001b[1;32m    376\u001b[0m     sources,\n\u001b[1;32m    377\u001b[0m     separator,\n\u001b[1;32m    378\u001b[0m     has_header,\n\u001b[1;32m    379\u001b[0m     ignore_errors,\n\u001b[1;32m    380\u001b[0m     skip_rows,\n\u001b[1;32m    381\u001b[0m     n_rows,\n\u001b[1;32m    382\u001b[0m     cache,\n\u001b[1;32m    383\u001b[0m     dtype_list,\n\u001b[1;32m    384\u001b[0m     low_memory,\n\u001b[1;32m    385\u001b[0m     comment_prefix,\n\u001b[1;32m    386\u001b[0m     quote_char,\n\u001b[1;32m    387\u001b[0m     processed_null_values,\n\u001b[1;32m    388\u001b[0m     missing_utf8_is_empty_string,\n\u001b[1;32m    389\u001b[0m     infer_schema_length,\n\u001b[1;32m    390\u001b[0m     with_column_names,\n\u001b[1;32m    391\u001b[0m     rechunk,\n\u001b[1;32m    392\u001b[0m     skip_rows_after_header,\n\u001b[1;32m    393\u001b[0m     encoding,\n\u001b[1;32m    394\u001b[0m     _prepare_row_count_args(row_count_name, row_count_offset),\n\u001b[1;32m    395\u001b[0m     try_parse_dates,\n\u001b[1;32m    396\u001b[0m     eol_char\u001b[39m=\u001b[39;49meol_char,\n\u001b[1;32m    397\u001b[0m     raise_if_empty\u001b[39m=\u001b[39;49mraise_if_empty,\n\u001b[1;32m    398\u001b[0m     truncate_ragged_lines\u001b[39m=\u001b[39;49mtruncate_ragged_lines,\n\u001b[1;32m    399\u001b[0m     schema\u001b[39m=\u001b[39;49mschema,\n\u001b[1;32m    400\u001b[0m )\n\u001b[1;32m    401\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or directory (os error 2): /Volumes/FelipeSSD/mimic_clinical/CHARTEVENTS.csv"
     ]
    }
   ],
   "source": [
    "# Define the data types for specific columns\n",
    "# Here, we specify that the \"VALUE\" column should be treated as a string (Utf8)\n",
    "dtypes = {\"VALUE\": pl.Utf8}\n",
    "\n",
    "# Define values that should be treated as null\n",
    "# \"Moves on Bed\" is specified as a null value\n",
    "null_values = [\"Moves on Bed\"]\n",
    "\n",
    "# Load the CHARTEVENTS CSV file using Polars with specific settings\n",
    "# infer_schema_length is set to 100000 to adjust the number of rows used to infer the schema\n",
    "# dtypes specifies the data types for columns\n",
    "# null_values specifies values that should be treated as null\n",
    "charevents = pl.scan_csv(CHARTEVENTS, infer_schema_length=100000, dtypes=dtypes, null_values=null_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering the Heart Rate Information\n",
    "During the search for the `ITEMID` related to the Heart Rate we found 211 and 220045. We opted to choose the one with the most the available. Therefore we opted to conduct the analysis with the 220045 ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_rate = charevents.filter(pl.col(\"ITEMID\") == 211)\n",
    "heart_rate = heart_rate.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_rate_2 = charevents.filter(pl.col(\"ITEMID\") == 220045)\n",
    "heart_rate_2 = heart_rate_2.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_patients = pl.read_csv('/Users/felipeakiomatsuoka/Desktop/PIBIC/csvs/chartevents_processed.csv')\n",
    "patients_ids = sorted(list(selected_patients['SUBJECT_ID'].unique()))\n",
    "\n",
    "#heart_rate_extubation_1 = heart_rate.filter(pl.col(\"SUBJECT_ID\").is_in(patients_ids))\n",
    "heart_rate_extubation_2 = heart_rate_2.filter(pl.col(\"SUBJECT_ID\").is_in(patients_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 71009 rows in the dataframe\n",
      "There are 318 unique patients\n",
      "There are 1121759 rows in the dataframe\n",
      "There are 3999 unique patients\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(heart_rate_extubation_1)} rows in the dataframe\")\n",
    "print(f\"There are {len(heart_rate_extubation_1['SUBJECT_ID'].unique())} unique patients\")\n",
    "print(f\"\" )\n",
    "\n",
    "print(f\"There are {len(heart_rate_extubation_2)} rows in the dataframe\")\n",
    "print(f\"There are {len(heart_rate_extubation_2['SUBJECT_ID'].unique())} unique patients\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match the Heart Rate with the Extubation Processed Dataset\n",
    "\n",
    "This section of the code reads in a processed dataset of patients and merges it with heart rate data to align heart rate measurements with the extubation process. The goal is to analyze heart rate trends in relation to the extubation events.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'heart_rate_extubation_2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/felipeakiomatsuoka/Desktop/PIBIC/scripts/heart_rate.ipynb Cell 15\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/felipeakiomatsuoka/Desktop/PIBIC/scripts/heart_rate.ipynb#X20sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m processed_patients \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39m/Users/felipeakiomatsuoka/Desktop/PIBIC/csvs/chartevents_processed.csv\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/felipeakiomatsuoka/Desktop/PIBIC/scripts/heart_rate.ipynb#X20sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m heart_rate_data \u001b[39m=\u001b[39m heart_rate_extubation_2[[\u001b[39m'\u001b[39m\u001b[39mSUBJECT_ID\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mICUSTAY_ID\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mCHARTTIME\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mVALUENUM\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mVALUEUOM\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/felipeakiomatsuoka/Desktop/PIBIC/scripts/heart_rate.ipynb#X20sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m heart_rate_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mmerge(processed_patients, heart_rate_data, on\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mICUSTAY_ID\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'heart_rate_extubation_2' is not defined"
     ]
    }
   ],
   "source": [
    "processed_patients = pd.read_csv('/Users/felipeakiomatsuoka/Desktop/PIBIC/csvs/chartevents_processed.csv')\n",
    "\n",
    "heart_rate_data = heart_rate_extubation_2[['SUBJECT_ID', 'ICUSTAY_ID', 'CHARTTIME', 'VALUENUM', 'VALUEUOM']]\n",
    "heart_rate_data = pd.merge(processed_patients, heart_rate_data, on='ICUSTAY_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ICUSTAY_ID</th>\n",
       "      <th>SUBJECT_ID_x</th>\n",
       "      <th>STARTTIME</th>\n",
       "      <th>ENDTIME</th>\n",
       "      <th>TIME_SPENT</th>\n",
       "      <th>PREVIOUS_PROCEDURE_END</th>\n",
       "      <th>TIME_SINCE_LAST_INTUBATION</th>\n",
       "      <th>START_ANALYSIS</th>\n",
       "      <th>END_ANALYSIS</th>\n",
       "      <th>LABEL</th>\n",
       "      <th>DEAD</th>\n",
       "      <th>DEATH_TIME</th>\n",
       "      <th>SUBJECT_ID_y</th>\n",
       "      <th>CHARTTIME</th>\n",
       "      <th>VALUENUM</th>\n",
       "      <th>VALUEUOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>200033.0</td>\n",
       "      <td>56369</td>\n",
       "      <td>2198-08-10 17:30:00</td>\n",
       "      <td>2198-08-20 12:20:00</td>\n",
       "      <td>234.833333</td>\n",
       "      <td>2198-08-10 17:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2198-08-20 12:20:00</td>\n",
       "      <td>2198-08-21 12:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2198-08-21 00:00:00</td>\n",
       "      <td>56369</td>\n",
       "      <td>2198-08-08 17:00:00</td>\n",
       "      <td>63.0</td>\n",
       "      <td>bpm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>200033.0</td>\n",
       "      <td>56369</td>\n",
       "      <td>2198-08-10 17:30:00</td>\n",
       "      <td>2198-08-20 12:20:00</td>\n",
       "      <td>234.833333</td>\n",
       "      <td>2198-08-10 17:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2198-08-20 12:20:00</td>\n",
       "      <td>2198-08-21 12:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2198-08-21 00:00:00</td>\n",
       "      <td>56369</td>\n",
       "      <td>2198-08-08 18:00:00</td>\n",
       "      <td>59.0</td>\n",
       "      <td>bpm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>200033.0</td>\n",
       "      <td>56369</td>\n",
       "      <td>2198-08-10 17:30:00</td>\n",
       "      <td>2198-08-20 12:20:00</td>\n",
       "      <td>234.833333</td>\n",
       "      <td>2198-08-10 17:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2198-08-20 12:20:00</td>\n",
       "      <td>2198-08-21 12:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2198-08-21 00:00:00</td>\n",
       "      <td>56369</td>\n",
       "      <td>2198-08-08 19:00:00</td>\n",
       "      <td>61.0</td>\n",
       "      <td>bpm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>200033.0</td>\n",
       "      <td>56369</td>\n",
       "      <td>2198-08-10 17:30:00</td>\n",
       "      <td>2198-08-20 12:20:00</td>\n",
       "      <td>234.833333</td>\n",
       "      <td>2198-08-10 17:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2198-08-20 12:20:00</td>\n",
       "      <td>2198-08-21 12:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2198-08-21 00:00:00</td>\n",
       "      <td>56369</td>\n",
       "      <td>2198-08-08 20:00:00</td>\n",
       "      <td>57.0</td>\n",
       "      <td>bpm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>200033.0</td>\n",
       "      <td>56369</td>\n",
       "      <td>2198-08-10 17:30:00</td>\n",
       "      <td>2198-08-20 12:20:00</td>\n",
       "      <td>234.833333</td>\n",
       "      <td>2198-08-10 17:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2198-08-20 12:20:00</td>\n",
       "      <td>2198-08-21 12:20:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2198-08-21 00:00:00</td>\n",
       "      <td>56369</td>\n",
       "      <td>2198-08-08 21:00:00</td>\n",
       "      <td>58.0</td>\n",
       "      <td>bpm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ICUSTAY_ID  SUBJECT_ID_x            STARTTIME  \\\n",
       "0           3    200033.0         56369  2198-08-10 17:30:00   \n",
       "1           3    200033.0         56369  2198-08-10 17:30:00   \n",
       "2           3    200033.0         56369  2198-08-10 17:30:00   \n",
       "3           3    200033.0         56369  2198-08-10 17:30:00   \n",
       "4           3    200033.0         56369  2198-08-10 17:30:00   \n",
       "\n",
       "               ENDTIME  TIME_SPENT PREVIOUS_PROCEDURE_END  \\\n",
       "0  2198-08-20 12:20:00  234.833333    2198-08-10 17:30:00   \n",
       "1  2198-08-20 12:20:00  234.833333    2198-08-10 17:30:00   \n",
       "2  2198-08-20 12:20:00  234.833333    2198-08-10 17:30:00   \n",
       "3  2198-08-20 12:20:00  234.833333    2198-08-10 17:30:00   \n",
       "4  2198-08-20 12:20:00  234.833333    2198-08-10 17:30:00   \n",
       "\n",
       "   TIME_SINCE_LAST_INTUBATION       START_ANALYSIS         END_ANALYSIS  \\\n",
       "0                         0.0  2198-08-20 12:20:00  2198-08-21 12:20:00   \n",
       "1                         0.0  2198-08-20 12:20:00  2198-08-21 12:20:00   \n",
       "2                         0.0  2198-08-20 12:20:00  2198-08-21 12:20:00   \n",
       "3                         0.0  2198-08-20 12:20:00  2198-08-21 12:20:00   \n",
       "4                         0.0  2198-08-20 12:20:00  2198-08-21 12:20:00   \n",
       "\n",
       "   LABEL  DEAD           DEATH_TIME  SUBJECT_ID_y            CHARTTIME  \\\n",
       "0      0     1  2198-08-21 00:00:00         56369  2198-08-08 17:00:00   \n",
       "1      0     1  2198-08-21 00:00:00         56369  2198-08-08 18:00:00   \n",
       "2      0     1  2198-08-21 00:00:00         56369  2198-08-08 19:00:00   \n",
       "3      0     1  2198-08-21 00:00:00         56369  2198-08-08 20:00:00   \n",
       "4      0     1  2198-08-21 00:00:00         56369  2198-08-08 21:00:00   \n",
       "\n",
       "   VALUENUM VALUEUOM  \n",
       "0      63.0      bpm  \n",
       "1      59.0      bpm  \n",
       "2      61.0      bpm  \n",
       "3      57.0      bpm  \n",
       "4      58.0      bpm  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "heart_rate_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze Heart Rate Data within a Fixed Interval Regarding the Extubation Procedure\n",
    "\n",
    "This section of the code filters the heart rate data to include only the measurements that fall within a specified analysis interval relative to the extubation procedure. The filtered data is then saved to a CSV file for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask to filter heart rate data within the analysis interval\n",
    "mask = (pd.to_datetime(heart_rate_data['CHARTTIME']) >= pd.to_datetime(heart_rate_data['START_ANALYSIS'])) & (pd.to_datetime(heart_rate_data['CHARTTIME']) <= pd.to_datetime(heart_rate_data['END_ANALYSIS']))\n",
    "\n",
    "# Apply the mask to get the heart rate data within the analysis interval\n",
    "heart_rate_data_in_analysis = heart_rate_data[mask]\n",
    "\n",
    "# Save the filtered data to a CSV file\n",
    "heart_rate_data_in_analysis.to_csv('/Users/felipeakiomatsuoka/Desktop/PIBIC/csvs/heart_rate_data_in_analysis.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Clean Heart Rate Data for Analysis\n",
    "\n",
    "This section of the code loads the heart rate data from a CSV file, drops unnecessary columns, selects relevant columns, and renames them for clarity. This prepares the data for further analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the heart rate data from the CSV file\n",
    "heart_rate = pd.read_csv('/Users/felipeakiomatsuoka/Desktop/PIBIC/csvs/heart_rate_data_in_analysis.csv')\n",
    "\n",
    "# Drop the unnecessary 'Unnamed: 0' column\n",
    "heart_rate = heart_rate.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# Select relevant columns for analysis\n",
    "heart_rate = heart_rate[['ICUSTAY_ID', 'VALUENUM', 'SUBJECT_ID_x', 'CHARTTIME', 'LABEL']]\n",
    "\n",
    "# Rename columns for clarity\n",
    "heart_rate = heart_rate.rename(columns={'SUBJECT_ID_x': 'SUBJECT_ID', 'VALUENUM': 'HEART_RATE'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Merge Patient Data for Heart Rate Analysis\n",
    "\n",
    "This section of the code loads patient admission and demographic data, merges it with heart rate data, and calculates the age of patients at the time of admission. The merged data is then filtered to include only relevant columns and heart rate values above a certain threshold that are physiologically possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load admissions data from CSV file\n",
    "admissions_df = pd.read_csv('/Users/felipeakiomatsuoka/Desktop/PIBIC/csvs/ADMISSIONS.csv')\n",
    "\n",
    "# Load patients data from CSV file\n",
    "patients_df = pd.read_csv('/Users/felipeakiomatsuoka/Desktop/PIBIC/csvs/PATIENTS.csv')\n",
    "\n",
    "# Merge admissions and patients data on 'SUBJECT_ID'\n",
    "merged_df = pd.merge(admissions_df, patients_df, on='SUBJECT_ID')\n",
    "\n",
    "# Convert 'ADMITTIME' and 'DOB' columns to datetime format\n",
    "merged_df['ADMITTIME'] = pd.to_datetime(merged_df['ADMITTIME'])\n",
    "merged_df['DOB'] = pd.to_datetime(merged_df['DOB'])\n",
    "\n",
    "# Function to calculate age in years at the time of admission\n",
    "def calculate_age(admit_time, dob):\n",
    "    admit_time_py = admit_time.to_pydatetime()\n",
    "    dob_py = dob.to_pydatetime()\n",
    "    age = (admit_time_py - dob_py).days / 365.25\n",
    "    return 89 if age > 89 else age  # Cap age at 89\n",
    "\n",
    "# Apply the age calculation function to each row\n",
    "merged_df['AGE'] = merged_df.apply(lambda row: calculate_age(row['ADMITTIME'], row['DOB']), axis=1)\n",
    "merged_df['AGE'] = merged_df['AGE'].astype(int)  # Convert age to integer\n",
    "\n",
    "# Merge heart rate data with the merged patient data on 'SUBJECT_ID'\n",
    "heart_rate = pd.merge(heart_rate, merged_df, on='SUBJECT_ID')\n",
    "\n",
    "# Select relevant columns for analysis\n",
    "heart_rate = heart_rate[['SUBJECT_ID', 'ICUSTAY_ID', 'AGE', 'GENDER', 'ETHNICITY', 'CHARTTIME', 'HEART_RATE', 'LABEL']]\n",
    "\n",
    "# Filter out heart rate values less than or equal to 30\n",
    "heart_rate = heart_rate.loc[heart_rate['HEART_RATE'] > 30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group and Analyze Heart Rate Data by ICU Stay\n",
    "\n",
    "This section of the code groups heart rate data by ICU stay, calculates various statistics, and merges these statistics with the original data. The final dataset is saved to a CSV file for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group heart rate data by 'ICUSTAY_ID' and calculate statistics\n",
    "grouped = heart_rate.groupby('ICUSTAY_ID')['HEART_RATE']\n",
    "grouped_stats = grouped.agg(['mean', 'median', 'std', 'var', 'min', 'max']).reset_index()\n",
    "\n",
    "# Calculate the range of heart rate values for each ICU stay\n",
    "grouped_stats['range'] = grouped_stats['max'] - grouped_stats['min']\n",
    "\n",
    "# Select relevant statistics columns\n",
    "grouped_stats = grouped_stats[['ICUSTAY_ID', 'mean', 'median', 'std', 'min', 'max', 'range']]\n",
    "\n",
    "# Count the number of heart rate measurements for each ICU stay\n",
    "counts = heart_rate.groupby('ICUSTAY_ID')['HEART_RATE'].count()\n",
    "\n",
    "# Merge the heart rate data with the counts\n",
    "icu_stays_heart_rate = pd.merge(heart_rate, counts, on='ICUSTAY_ID')\n",
    "\n",
    "# Drop duplicate rows, keeping the first occurrence\n",
    "icu_stays_heart_rate = icu_stays_heart_rate.drop_duplicates(subset='ICUSTAY_ID', keep='first')\n",
    "\n",
    "# Rename columns for clarity\n",
    "icu_stays_heart_rate = icu_stays_heart_rate.rename(columns={'HEART_RATE_x': 'HEART_RATE', 'HEART_RATE_y': 'COUNT'})\n",
    "\n",
    "# Drop unnecessary columns\n",
    "icu_stays_heart_rate = icu_stays_heart_rate.drop(columns=['CHARTTIME', 'HEART_RATE'])\n",
    "\n",
    "# Merge the heart rate data with the grouped statistics\n",
    "icu_stays_heart_rate = pd.merge(icu_stays_heart_rate, grouped_stats, on='ICUSTAY_ID')\n",
    "\n",
    "# Rename the 'LABEL' column to 'EXTUBATION_FAILURE'\n",
    "icu_stays_heart_rate = icu_stays_heart_rate.rename(columns={'LABEL': 'EXTUBATION_FAILURE'})\n",
    "\n",
    "# Display the first few rows of the final dataset\n",
    "icu_stays_heart_rate.head()\n",
    "\n",
    "# Get the length of the 'EXTUBATION_FAILURE' column\n",
    "len(icu_stays_heart_rate['EXTUBATION_FAILURE'])\n",
    "\n",
    "# Save the final dataset to a CSV file\n",
    "icu_stays_heart_rate.to_csv('/Users/felipeakiomatsuoka/Desktop/PIBIC/csvs/final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
